{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"detection-datasets/fashionpedia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install 'git+https://github.com/facebookresearch/detectron2.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "\n",
    "# # Replace 'path/to/your/image.jpg' with the actual path to your image\n",
    "# image_path = 'test2.png'\n",
    "# image = Image.open(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, AutoModelForObjectDetection\n",
    "\n",
    "# Load the processor and model\n",
    "processor = AutoImageProcessor.from_pretrained(\"valentinafeve/yolos-fashionpedia\")\n",
    "model = AutoModelForObjectDetection.from_pretrained(\"valentinafeve/yolos-fashionpedia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (1592, 896, 3)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Replace 'Chippewa.png' with the actual path to your image\n",
    "image_path = 'test2.png'\n",
    "\n",
    "# Load the image and ensure it's in RGB format\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "# Convert the PIL Image to a NumPy array\n",
    "image_array = np.array(image)\n",
    "\n",
    "# Debugging: Print the shape of the image array\n",
    "print('Image shape:', image_array.shape)  # Should be (height, width, 3)\n",
    "\n",
    "# Preprocess the image\n",
    "inputs = processor(images=image_array, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-process the outputs to get object detection results\n",
    "results = processor.post_process_object_detection(\n",
    "    outputs, threshold=0.5, target_sizes=[image.size[::-1]]\n",
    ")\n",
    "result = results[0]  # Since we have only one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load category mappings\n",
    "with open('/Users/joshstrupp/Documents/Working/Educational/MSDV/ms1-final/fashionpedia-api/data/demo/category_attributes_descriptions.json', 'r') as f:\n",
    "    category_data = json.load(f)\n",
    "\n",
    "# Create mappings from category IDs to names and supercategories\n",
    "categories = category_data['categories']\n",
    "category_id_to_name = {category['id']: category['name'] for category in categories}\n",
    "category_id_to_supercategory = {category['id']: category['supercategory'] for category in categories}\n",
    "\n",
    "# Create a mapping from label IDs to category names (from the model)\n",
    "label_mappings = model.config.id2label  # This maps label IDs to category names\n",
    "\n",
    "# Create a mapping from category names to supercategories\n",
    "name_to_supercategory = {category['name']: category['supercategory'] for category in categories}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image ID: 0\n",
      "Width: 896\n",
      "Height: 1592\n",
      "Objects Detected:\n",
      "  Object 1:\n",
      "    Bounding Box ID: 0\n",
      "    Category ID: 33\n",
      "    Name: neckline\n",
      "    Supercategory: garment parts\n",
      "    Bounding Box: [376.6819152832031, 381.1187744140625, 561.2196044921875, 485.8564453125]\n",
      "    Area: 19328.047760728747\n",
      "  Object 2:\n",
      "    Bounding Box ID: 1\n",
      "    Category ID: 15\n",
      "    Name: headband, head covering, hair accessory\n",
      "    Supercategory: head\n",
      "    Bounding Box: [283.3788757324219, 126.98322296142578, 531.8199462890625, 313.0384216308594]\n",
      "    Area: 46223.75274006254\n",
      "  Object 3:\n",
      "    Bounding Box ID: 2\n",
      "    Category ID: 10\n",
      "    Name: dress\n",
      "    Supercategory: wholebody\n",
      "    Bounding Box: [14.879779815673828, 390.08843994140625, 736.210205078125, 1500.7442626953125]\n",
      "    Area: 801149.8369472928\n",
      "  Object 4:\n",
      "    Bounding Box ID: 3\n",
      "    Category ID: 31\n",
      "    Name: sleeve\n",
      "    Supercategory: garment parts\n",
      "    Bounding Box: [552.6659545898438, 431.0205078125, 715.664794921875, 667.8580322265625]\n",
      "    Area: 38604.24182660133\n"
     ]
    }
   ],
   "source": [
    "# Prepare the objects data\n",
    "objects = {\n",
    "    'bbox_id': [],\n",
    "    'category': [],\n",
    "    'bbox': [],\n",
    "    'area': [],\n",
    "    'supercategory': [],\n",
    "    'name': []\n",
    "}\n",
    "\n",
    "for idx in range(len(result['scores'])):\n",
    "    score = result['scores'][idx].item()\n",
    "    label_id = result['labels'][idx].item()\n",
    "    box = result['boxes'][idx].tolist()  # [xmin, ymin, xmax, ymax]\n",
    "\n",
    "    # Compute area\n",
    "    x_min, y_min, x_max, y_max = box\n",
    "    area = (x_max - x_min) * (y_max - y_min)\n",
    "\n",
    "    # Get category name from label ID\n",
    "    name = label_mappings.get(label_id, 'Unknown')\n",
    "    supercategory = name_to_supercategory.get(name, 'Unknown')\n",
    "\n",
    "    # Map category name back to category ID from the dataset if needed\n",
    "    category_id = next((id for id, n in category_id_to_name.items() if n == name), label_id)\n",
    "\n",
    "    # Append to objects\n",
    "    objects['bbox_id'].append(idx)\n",
    "    objects['category'].append(category_id)\n",
    "    objects['bbox'].append(box)\n",
    "    objects['area'].append(area)\n",
    "    objects['name'].append(name)\n",
    "    objects['supercategory'].append(supercategory)\n",
    "\n",
    "# Get image dimensions\n",
    "width, height = image.size\n",
    "\n",
    "# Compile the final output\n",
    "output = {\n",
    "    'image_id': 0,  # Assign an ID to your image\n",
    "    'image': image,\n",
    "    'width': width,\n",
    "    'height': height,\n",
    "    'objects': objects\n",
    "}\n",
    "\n",
    "# Print the analysis\n",
    "print(\"Image ID:\", output['image_id'])\n",
    "print(\"Width:\", output['width'])\n",
    "print(\"Height:\", output['height'])\n",
    "print(\"Objects Detected:\")\n",
    "for i in range(len(objects['bbox_id'])):\n",
    "    print(f\"  Object {i+1}:\")\n",
    "    print(f\"    Bounding Box ID: {objects['bbox_id'][i]}\")\n",
    "    print(f\"    Category ID: {objects['category'][i]}\")\n",
    "    print(f\"    Name: {objects['name'][i]}\")\n",
    "    print(f\"    Supercategory: {objects['supercategory'][i]}\")\n",
    "    print(f\"    Bounding Box: {objects['bbox'][i]}\")\n",
    "    print(f\"    Area: {objects['area'][i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image(image_path, category_json_path='category_attributes_descriptions.json'):\n",
    "    \"\"\"\n",
    "    Analyzes an image using the Fashionpedia model and returns a DataFrame with the outputs.\n",
    "\n",
    "    Parameters:\n",
    "    - image_path (str): The path to the image file.\n",
    "    - category_json_path (str): The path to the category attributes JSON file.\n",
    "\n",
    "    Returns:\n",
    "    - df (pandas.DataFrame): A DataFrame containing the analysis results.\n",
    "    \"\"\"\n",
    "    from PIL import Image\n",
    "    from transformers import AutoImageProcessor, AutoModelForObjectDetection\n",
    "    import pandas as pd\n",
    "    import torch\n",
    "    import json\n",
    "    import numpy as np\n",
    "\n",
    "    # 1. Load your image\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Ensure image is in RGB format\n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert('RGB')\n",
    "\n",
    "    # Convert the image to a NumPy array\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    # 2. Load the processor and model\n",
    "    processor = AutoImageProcessor.from_pretrained(\"valentinafeve/yolos-fashionpedia\")\n",
    "    model = AutoModelForObjectDetection.from_pretrained(\"valentinafeve/yolos-fashionpedia\")\n",
    "\n",
    "    # 3. Prepare the image\n",
    "    inputs = processor(images=image_array, return_tensors=\"pt\")\n",
    "\n",
    "    # 4. Run inference\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # 5. Process the outputs\n",
    "    results = processor.post_process_object_detection(\n",
    "        outputs, threshold=0.8, target_sizes=[image.size[::-1]]\n",
    "    )\n",
    "    result = results[0]\n",
    "\n",
    "    # 6. Map category IDs to names and supercategories\n",
    "    with open(category_json_path, 'r') as f:\n",
    "        category_data = json.load(f)\n",
    "    categories = category_data['categories']\n",
    "    category_id_to_name = {category['id']: category['name'] for category in categories}\n",
    "    category_id_to_supercategory = {category['id']: category['supercategory'] for category in categories}\n",
    "\n",
    "    label_mappings = model.config.id2label\n",
    "    name_to_supercategory = {category['name']: category['supercategory'] for category in categories}\n",
    "\n",
    "    # 7. Prepare data for DataFrame\n",
    "    data = []\n",
    "    for idx in range(len(result['scores'])):\n",
    "        score = result['scores'][idx].item()\n",
    "        label_id = result['labels'][idx].item()\n",
    "        box = result['boxes'][idx].tolist()\n",
    "        x_min, y_min, x_max, y_max = box\n",
    "        area = (x_max - x_min) * (y_max - y_min)\n",
    "\n",
    "        name = label_mappings.get(label_id, 'Unknown')\n",
    "        supercategory = name_to_supercategory.get(name, 'Unknown')\n",
    "        category_id = next((id for id, n in category_id_to_name.items() if n == name), label_id)\n",
    "\n",
    "        data.append({\n",
    "            'bbox_id': idx,\n",
    "            'category_id': category_id,\n",
    "            'name': name,\n",
    "            'supercategory': supercategory,\n",
    "            'bbox': box,\n",
    "            'area': area,\n",
    "            'score': score\n",
    "        })\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Replace 'path/to/your/image.jpg' with the actual path to your image\n",
    "image_path = 'test2.png'\n",
    "\n",
    "# Optionally, specify the path to your category attributes JSON file\n",
    "category_json_path = '../category_attributes_descriptions.json'\n",
    "\n",
    "# Call the function\n",
    "df = analyze_image(image_path, category_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cropped image: cropped_images/Angola Costume_neckline_0.jpg\n",
      "Saved cropped image: cropped_images/Angola Costume_dress_1.jpg\n",
      "Saved cropped image: cropped_images/Angola Costume_sleeve_2.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def save_cropped_images(image_path, df, output_dir='cropped_images'):\n",
    "    \"\"\"\n",
    "    Crops the original image according to the bounding boxes and saves the cropped images.\n",
    "\n",
    "    Parameters:\n",
    "    - image_path (str): Path to the original image.\n",
    "    - df (pandas.DataFrame): DataFrame containing the detection results.\n",
    "    - output_dir (str): Directory where the cropped images will be saved.\n",
    "    \"\"\"\n",
    "    from PIL import Image\n",
    "    import os\n",
    "\n",
    "    # Load the image\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Ensure image is in RGB format\n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert('RGB')\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Get image dimensions\n",
    "    width, height = image.size\n",
    "\n",
    "    # Loop over each detection\n",
    "    for idx, row in df.iterrows():\n",
    "        bbox = row['bbox']\n",
    "        name = row['name']\n",
    "\n",
    "        # Extract bounding box coordinates\n",
    "        x_min, y_min, x_max, y_max = map(int, bbox)\n",
    "\n",
    "        # Clip coordinates to image bounds\n",
    "        x_min = max(0, min(width, x_min))\n",
    "        y_min = max(0, min(height, y_min))\n",
    "        x_max = max(0, min(width, x_max))\n",
    "        y_max = max(0, min(height, y_max))\n",
    "\n",
    "        # Check for valid crop\n",
    "        if x_max > x_min and y_max > y_min:\n",
    "            # Crop the image\n",
    "            cropped_image = image.crop((x_min, y_min, x_max, y_max))\n",
    "\n",
    "            # Ensure cropped image is in RGB mode\n",
    "            if cropped_image.mode != 'RGB':\n",
    "                cropped_image = cropped_image.convert('RGB')\n",
    "\n",
    "            # Create a unique filename\n",
    "            image_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "            filename = f\"{image_name}_{name.replace(' ', '_')}_{idx}.jpg\"\n",
    "            output_path = os.path.join(output_dir, filename)\n",
    "\n",
    "            try:\n",
    "                # Save the cropped image\n",
    "                cropped_image.save(output_path, format='JPEG')\n",
    "                print(f\"Saved cropped image: {output_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to save {output_path}: {e}\")\n",
    "        else:\n",
    "            print(f\"Skipping invalid crop for detection {idx}\")\n",
    "\n",
    "# Assume df is the DataFrame obtained from analyze_image\n",
    "image_path = 'Angola Costume.png'  # Replace with your image path\n",
    "\n",
    "# Check if output directory exists, if not create it\n",
    "if not os.path.exists('cropped_images'):\n",
    "    os.makedirs('cropped_images')\n",
    "\n",
    "# Call the function to save cropped images, ensuring unique filenames\n",
    "existing_files = set(os.listdir('cropped_images'))\n",
    "counter = 1\n",
    "while any(f\"{os.path.splitext(os.path.basename(image_path))[0]}_{counter}\" in f for f in existing_files):\n",
    "    counter += 1\n",
    "save_cropped_images(image_path, df, output_dir='cropped_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
